{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 103089 - Data mining\n",
    "\n",
    "<center><img src=\"M-UdL2.png\"  width=\"300\" alt=\"Italian Trulli\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2: Cosine similarity for movie comparison \n",
    "\n",
    "In this exercise you have to implement in a python notebook using the spark framework:\n",
    "\n",
    "1. The distributed (map/reduce) algorithm of slide \"3.7\" (in notebook \"8-Item-to-Items-globalfiltering-recommenders-py3-sshow.ipynb\") for computing the cosine similarity of a set of products with negative and positive ratings, using as input information an RDD (or spark dataframe that is also distributed) with ratings with this format:\n",
    "\n",
    "- (userID,movieID,rating)\n",
    "\n",
    "2. The computation of the Cosine Similarity (with the previous algorithm) of all the pairs of movies from the different files you have with this exercise:\n",
    "\n",
    "- filtered50movies.csv\n",
    "\n",
    "- filtered100movies.csv\n",
    "\n",
    "- filtered150movies.csv\n",
    "\n",
    "- filtered200movies.csv\n",
    "\n",
    "Each file contains ratings for a different set of movies, but the ones in a smaller file are always a subset of a file with bigger size. We provide files with different size in case you have some memory issues in your computer, so use the biggest file you are able to use, although during \"testing\" of your code you can of course use the smallest file, or even any smaller subset of the file filtered50movies.csv.\n",
    "\n",
    "3. Show on the screen the information for the \"top 10\" most similar pairs, but using the name of the movies you can find in the  movies file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1: Initialization of PySpark\n",
    "\n",
    "This cell initializes PySpark, a Python library for Spark, a big data processing framework. It sets up the environment, specifies the Python version to use, and creates a SparkContext (sc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/07 18:14:43 WARN Utils: Your hostname, Jordis-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.226.52 instead (on interface en0)\n",
      "23/11/07 18:14:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/07 18:14:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.226.52:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import os\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON3\"] = \"python\"\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "print (spark_home)\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "sc.setLogLevel('ERROR')\n",
    "sc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
