{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"actividad2_150.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"cells":[{"cell_type":"code","metadata":{"id":"TKqWyZ1O_4Th","outputId":"141be544-5c40-42c7-b821-5d41468608d5"},"source":["!pip install pyspark\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyspark in /home/bigdata/.local/lib/python3.8/site-packages (3.2.0)\n","Requirement already satisfied: py4j==0.10.9.2 in /home/bigdata/.local/lib/python3.8/site-packages (from pyspark) (0.10.9.2)\n"]}]},{"cell_type":"code","metadata":{"id":"rvStokvt_4Tl","outputId":"a7e1f415-2b0a-4eeb-c5d5-e646d9246735"},"source":["from pyspark.sql import SparkSession\n","\n","\n","SPARK_ENDPOINT = \"local[*]\"\n","sparkSession = SparkSession.builder \\\n","    .master(SPARK_ENDPOINT) \\\n","    .getOrCreate()\n","sparkContext = sparkSession.sparkContext\n","sparkSession\n"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["21/11/16 20:24:59 WARN Utils: Your hostname, bigdata resolves to a loopback address: 127.0.1.1; using 192.168.163.133 instead (on interface ens33)\n","21/11/16 20:24:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","21/11/16 20:25:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","21/11/16 20:25:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","21/11/16 20:25:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n","21/11/16 20:25:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n","21/11/16 20:25:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://192.168.163.133:4044\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f3c119a7880>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"yH3BTkbB_4Tn","outputId":"1dd2c976-acab-4d1e-e177-ab009ec496fd"},"source":["from pyspark.sql.functions import col\n","from pyspark.sql.types import IntegerType, StringType, StructField, StructType\n","\n","\n","MOVIES_INPUT_PATH = \"movies.csv\"\n","moviesDataFrame = sparkSession.read.csv(MOVIES_INPUT_PATH, header = True) \\\n","    .withColumn(\"MovieId\", col(\"MovieId\").cast(IntegerType())) \\\n","    .withColumn(\"Title\", col(\"Title\").cast(StringType())) \\\n","    .withColumn(\"Genres\", col(\"Genres\").cast(StringType()))\n","moviesDataFrame.show()\n","moviesRdd = moviesDataFrame.rdd.map(lambda x: (int(x[0]), str(x[1]), str(x[2])))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+--------------------+--------------------+\n","|MovieId|               Title|              Genres|\n","+-------+--------------------+--------------------+\n","|      1|    Toy Story (1995)|Adventure|Animati...|\n","|      2|      Jumanji (1995)|Adventure|Childre...|\n","|      3|Grumpier Old Men ...|      Comedy|Romance|\n","|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n","|      5|Father of the Bri...|              Comedy|\n","|      6|         Heat (1995)|Action|Crime|Thri...|\n","|      7|      Sabrina (1995)|      Comedy|Romance|\n","|      8| Tom and Huck (1995)|  Adventure|Children|\n","|      9| Sudden Death (1995)|              Action|\n","|     10|    GoldenEye (1995)|Action|Adventure|...|\n","|     11|American Presiden...|Comedy|Drama|Romance|\n","|     12|Dracula: Dead and...|       Comedy|Horror|\n","|     13|        Balto (1995)|Adventure|Animati...|\n","|     14|        Nixon (1995)|               Drama|\n","|     15|Cutthroat Island ...|Action|Adventure|...|\n","|     16|       Casino (1995)|         Crime|Drama|\n","|     17|Sense and Sensibi...|       Drama|Romance|\n","|     18|   Four Rooms (1995)|              Comedy|\n","|     19|Ace Ventura: When...|              Comedy|\n","|     20|  Money Train (1995)|Action|Comedy|Cri...|\n","+-------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"wWv7JZyV_4To","outputId":"72ff8a71-6357-42f5-b573-7c08d3ad8ded"},"source":["from pyspark.sql.functions import col\n","from pyspark.sql.types import FloatType, IntegerType\n","\n","\n","INPUT_PATH = \"filtered150movies.csv\"\n","dataFrame = sparkSession.read.csv(INPUT_PATH, header = True) \\\n","    .withColumn(\"UserId\", col(\"UserId\").cast(IntegerType())) \\\n","    .withColumn(\"MovieId\", col(\"MovieId\").cast(IntegerType())) \\\n","    .withColumn(\"Rating\", col(\"Rating\").cast(FloatType()))\n","dataFrame.show()\n","rdd = dataFrame.rdd.map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["+------+-------+------+\n","|UserId|MovieId|Rating|\n","+------+-------+------+\n","|     1|      1|   1.5|\n","|     5|      1|   1.5|\n","|     7|      1|   2.0|\n","|    15|      1|  -0.5|\n","|    17|      1|   2.0|\n","|    18|      1|   1.0|\n","|    19|      1|   1.5|\n","|    21|      1|   1.0|\n","|    27|      1|   0.5|\n","|    31|      1|   2.5|\n","|    32|      1|   0.5|\n","|    33|      1|   0.5|\n","|    40|      1|   2.5|\n","|    43|      1|   2.5|\n","|    44|      1|   0.5|\n","|    45|      1|   1.5|\n","|    46|      1|   2.5|\n","|    50|      1|   0.5|\n","|    54|      1|   0.5|\n","|    57|      1|   2.5|\n","+------+-------+------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"XfMZWkNP_4Ts","outputId":"7483bf4e-07a0-4037-9c2f-526177de88ba"},"source":["cartesianRdd = rdd.cartesian(rdd) \\\n","    .map(lambda x: (\n","        (x[0][0], x[0][1], x[0][2]), \n","        (x[1][0], x[1][1], x[1][2])\n","    )) \\\n","    .filter(lambda x: x[0][0] == x[1][0]) \\\n","    .filter(lambda x: x[0][1] < x[1][1])\n","cartesianDataFrame = sparkSession.createDataFrame(cartesianRdd, [\"(u, p1, r1)\", \"(u, p2, r2)\"])\n","cartesianDataFrame.show()\n"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["+-----------+-------------+\n","|(u, p1, r1)|  (u, p2, r2)|\n","+-----------+-------------+\n","|{1, 1, 1.5}|  {1, 3, 1.5}|\n","|{1, 1, 1.5}|  {1, 6, 1.5}|\n","|{1, 1, 1.5}| {1, 47, 2.5}|\n","|{1, 1, 1.5}| {1, 50, 2.5}|\n","|{1, 1, 1.5}| {1, 70, 0.5}|\n","|{1, 1, 1.5}|{1, 110, 1.5}|\n","|{1, 1, 1.5}|{1, 151, 2.5}|\n","|{1, 1, 1.5}|{1, 163, 2.5}|\n","|{1, 1, 1.5}|{1, 216, 2.5}|\n","|{1, 1, 1.5}|{1, 223, 0.5}|\n","|{1, 1, 1.5}|{1, 231, 2.5}|\n","|{1, 1, 1.5}|{1, 235, 1.5}|\n","|{1, 1, 1.5}|{1, 260, 2.5}|\n","|{1, 1, 1.5}|{1, 296, 0.5}|\n","|{1, 1, 1.5}|{1, 316, 0.5}|\n","|{1, 1, 1.5}|{1, 333, 2.5}|\n","|{1, 1, 1.5}|{1, 349, 1.5}|\n","|{1, 1, 1.5}|{1, 356, 1.5}|\n","|{1, 1, 1.5}|{1, 362, 2.5}|\n","|{1, 1, 1.5}|{1, 367, 1.5}|\n","+-----------+-------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/opt/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n","  File \"/opt/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n","  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 663, in main\n","    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n","  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n","    raise EOFError\n","EOFError\n"]}]},{"cell_type":"code","metadata":{"id":"vJuNFrWH_4Tu","outputId":"690d8dbf-714f-40d1-a89a-51b4c655caca"},"source":["from math import pow\n","\n","\n","userProductRatingsRdd = cartesianRdd.map(lambda x: (\n","    (x[0][1], x[1][1]), \n","    (x[0][2] * x[1][2], pow(x[0][2], 2), pow(x[1][2], 2))\n","))\n","userProductRatingsDataFrame = sparkSession.createDataFrame(userProductRatingsRdd, [\"(p1, p2)\", \"(r1 * r2, r1^2, r2^2)\"])\n","userProductRatingsDataFrame.show()"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["+--------+---------------------+\n","|(p1, p2)|(r1 * r2, r1^2, r2^2)|\n","+--------+---------------------+\n","|  {1, 3}|   {2.25, 2.25, 2.25}|\n","|  {1, 6}|   {2.25, 2.25, 2.25}|\n","| {1, 47}|   {3.75, 2.25, 6.25}|\n","| {1, 50}|   {3.75, 2.25, 6.25}|\n","| {1, 70}|   {0.75, 2.25, 0.25}|\n","|{1, 110}|   {2.25, 2.25, 2.25}|\n","|{1, 151}|   {3.75, 2.25, 6.25}|\n","|{1, 163}|   {3.75, 2.25, 6.25}|\n","|{1, 216}|   {3.75, 2.25, 6.25}|\n","|{1, 223}|   {0.75, 2.25, 0.25}|\n","|{1, 231}|   {3.75, 2.25, 6.25}|\n","|{1, 235}|   {2.25, 2.25, 2.25}|\n","|{1, 260}|   {3.75, 2.25, 6.25}|\n","|{1, 296}|   {0.75, 2.25, 0.25}|\n","|{1, 316}|   {0.75, 2.25, 0.25}|\n","|{1, 333}|   {3.75, 2.25, 6.25}|\n","|{1, 349}|   {2.25, 2.25, 2.25}|\n","|{1, 356}|   {2.25, 2.25, 2.25}|\n","|{1, 362}|   {3.75, 2.25, 6.25}|\n","|{1, 367}|   {2.25, 2.25, 2.25}|\n","+--------+---------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":[]}]},{"cell_type":"code","metadata":{"id":"VC_lbC6R_4Tu","outputId":"0045f415-268c-444c-9a76-c0b4974dee29"},"source":["step2Rdd = userProductRatingsRdd.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n","step2DataFrame = sparkSession.createDataFrame(step2Rdd, [\"(p1, p2)\", \"(pra1,2 + prb1,2, ra1^2 + rb1^2, ra2^2 + rb2^2)\"])\n","step2DataFrame.show()"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["+--------+-----------------------------------------------+\n","|(p1, p2)|(pra1,2 + prb1,2, ra1^2 + rb1^2, ra2^2 + rb2^2)|\n","+--------+-----------------------------------------------+\n","|  {1, 3}|                            {48.0, 88.25, 51.5}|\n","|  {1, 6}|                           {119.0, 150.25, 1...|\n","| {1, 47}|                           {190.0, 243.5, 29...|\n","| {1, 50}|                           {240.25, 255.0, 3...|\n","| {1, 70}|                           {31.75, 68.75, 61...|\n","|{1, 110}|                           {227.75, 287.25, ...|\n","|{1, 151}|                           {37.25, 51.75, 42.0}|\n","|{1, 163}|                            {66.5, 80.0, 88.25}|\n","|{1, 216}|                           {27.75, 100.75, 6...|\n","|{1, 223}|                           {98.0, 139.5, 153.5}|\n","|{1, 231}|                           {42.25, 201.75, 1...|\n","|{1, 235}|                           {67.5, 101.25, 86...|\n","|{1, 260}|                           {327.25, 349.5, 5...|\n","|{1, 296}|                           {326.25, 375.75, ...|\n","|{1, 316}|                           {65.25, 185.5, 96.5}|\n","|{1, 333}|                           {45.5, 66.25, 68.75}|\n","|{1, 349}|                           {74.5, 144.0, 73.25}|\n","|{1, 356}|                           {362.0, 402.0, 51...|\n","|{1, 362}|                           {31.0, 55.75, 49.25}|\n","|{1, 367}|                           {94.0, 257.5, 153...|\n","+--------+-----------------------------------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":[]}]},{"cell_type":"code","metadata":{"id":"gVS8Pi6B_4Tv","outputId":"2d76e8dd-2a4a-44d3-da75-4cd8b4394033"},"source":["from math import sqrt\n","\n","\n","cosineRdd = step2Rdd.map(lambda x: (\n","    x[0][0], \n","    x[0][1], \n","    x[1][0] / ( sqrt(x[1][1]) * sqrt(x[1][2]) )\n","))\n","cosineDataFrame = sparkSession.createDataFrame(cosineRdd, [\"Movie1Id\", \"Movie2Id\", \"CosineDistance\"])\n","cosineDataFrame.show()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+--------+-------------------+\n","|Movie1Id|Movie2Id|     CosineDistance|\n","+--------+--------+-------------------+\n","|       1|       3| 0.7120004462365306|\n","|       1|       6| 0.7663059588674602|\n","|       1|      47| 0.7134624997997026|\n","|       1|      50| 0.8064987231508762|\n","|       1|      70|0.48729156902469273|\n","|       1|     110| 0.7012089727414182|\n","|       1|     151|  0.798999403009002|\n","|       1|     163| 0.7914423667141078|\n","|       1|     216|0.34970388040486955|\n","|       1|     223| 0.6697069130757897|\n","|       1|     231|0.27013388711672426|\n","|       1|     235| 0.7223151185146152|\n","|       1|     260| 0.7628811383332508|\n","|       1|     296| 0.7324602560370937|\n","|       1|     316|0.48769118113363935|\n","|       1|     333| 0.6741896857847387|\n","|       1|     349| 0.7253894119809242|\n","|       1|     356| 0.7946310146221903|\n","|       1|     362| 0.5916108640359643|\n","|       1|     367| 0.4724236978477104|\n","+--------+--------+-------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"kYidVb-p_4Ty","outputId":"dfb486c3-1ffc-4f81-9c16-5c7bbb570c2a"},"source":["movies1DataFrame = sparkSession.createDataFrame(moviesRdd, [\"MovieId1\", \"Title1\", \"Genres1\"])\n","movies2DataFrame = sparkSession.createDataFrame(moviesRdd, [\"MovieId2\", \"Title2\", \"Genres2\"])\n","cosineWithTitlesRdd = cosineDataFrame \\\n","    .join(movies1DataFrame, cosineDataFrame.Movie1Id == movies1DataFrame.MovieId1, \"inner\") \\\n","    .join(movies2DataFrame, cosineDataFrame.Movie2Id == movies2DataFrame.MovieId2, \"inner\") \\\n","    .rdd \\\n","    .map(lambda x: (x[0], x[4], x[1], x[7], x[2])) \\\n","    .sortBy(lambda x: -x[4])\n","cosineWithTitlesDataFrame = sparkSession.createDataFrame(cosineWithTitlesRdd, [\"MovieId1\", \"MovieTitle1\", \"MovieId2\", \"MovieTitle2\", \"CosineDistance\"])\n","cosineWithTitlesDataFrame.show(10)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+--------------------+--------+--------------------+------------------+\n","|MovieId1|         MovieTitle1|MovieId2|         MovieTitle2|    CosineDistance|\n","+--------+--------------------+--------+--------------------+------------------+\n","|     151|      Rob Roy (1995)|     441|Dazed and Confuse...|               1.0|\n","|     260|Star Wars: Episod...|    1196|Star Wars: Episod...|0.9560939845339547|\n","|    1090|      Platoon (1986)|    1213|   Goodfellas (1990)|0.9504490201227582|\n","|     661|James and the Gia...|     923| Citizen Kane (1941)|0.9476070829586856|\n","|     151|      Rob Roy (1995)|    1080|Monty Python's Li...|0.9472110029417574|\n","|     923| Citizen Kane (1941)|    1587|Conan the Barbari...|0.9435183924675248|\n","|     151|      Rob Roy (1995)|    2329|American History ...|0.9434864536402258|\n","|    1198|Raiders of the Lo...|    1291|Indiana Jones and...| 0.942606433250396|\n","|     362|Jungle Book, The ...|    1587|Conan the Barbari...|0.9417419115948374|\n","|     923| Citizen Kane (1941)|    1617|L.A. Confidential...| 0.941241407642987|\n","+--------+--------------------+--------+--------------------+------------------+\n","only showing top 10 rows\n","\n"]}]}]}